{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8b3d57-ac14-4966-8384-97078f52052c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba9e5f-e7e0-41c1-b65d-d9ba1bcff64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sahi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26cf39b9-24fa-4658-83ab-c43cddf60e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sahi import AutoDetectionModel\n",
    "from sahi.predict import get_sliced_prediction, get_prediction\n",
    "from sahi.utils.cv import read_image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "\n",
    "\n",
    "class ObjectDetectionProcessor:\n",
    "    def __init__(self, ckpt_path, input_dir, output_dir, device='cpu', confidence_thresholds=None, image_size=640):\n",
    "        self.ckpt_path = ckpt_path\n",
    "        self.input_dir = input_dir\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "\n",
    "        self.default_confidence_threshold = 0.25\n",
    "\n",
    "        self.confidence_thresholds = confidence_thresholds if confidence_thresholds else {}\n",
    "\n",
    "        self.detection_model = AutoDetectionModel.from_pretrained(\n",
    "            model_type='yolov8',\n",
    "            model_path=self.ckpt_path,\n",
    "            confidence_threshold=self.default_confidence_threshold,\n",
    "            image_size=image_size,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "    def apply_custom_nms(self, boxes, scores, predictions, iou_threshold=0.8):\n",
    "        indices = cv2.dnn.NMSBoxes(boxes, scores, score_threshold=self.default_confidence_threshold, nms_threshold=iou_threshold)\n",
    "        if len(indices) == 0:\n",
    "            return []\n",
    "        indices = indices.flatten()\n",
    "        best_predictions = [predictions[i] for i in indices]\n",
    "        return best_predictions\n",
    "\n",
    "    def get_intersecting_box(self, box1, box2):\n",
    "        x1 = min(box1[0], box2[0])\n",
    "        y1 = min(box1[1], box2[1])\n",
    "        x2 = max(box1[2], box2[2])\n",
    "        y2 = max(box1[3], box2[3])\n",
    "        return x1, y1, x2, y2\n",
    "\n",
    "    def has_intersection(self, box1, box2, threshold=0.3):\n",
    "        intersection_area = self.calculate_intersection_area(box1, box2)\n",
    "        box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "\n",
    "        if box1_area == 0 or box2_area == 0:\n",
    "            return False\n",
    "\n",
    "        intersection_ratio = intersection_area / min(box1_area, box2_area)\n",
    "        return intersection_ratio > threshold\n",
    "\n",
    "    def calculate_intersection_area(self, box1, box2):\n",
    "        x1 = max(box1[0], box2[0])\n",
    "        y1 = max(box1[1], box2[1])\n",
    "        x2 = min(box1[2], box2[2])\n",
    "        y2 = min(box1[3], box2[3])\n",
    "\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            return 0\n",
    "        return (x2 - x1) * (y2 - y1)\n",
    "\n",
    "    def filter_predictions_by_confidence(self, predictions):\n",
    "        filtered_predictions = []\n",
    "        for pred in predictions:\n",
    "            class_id = pred.category.id\n",
    "            threshold = self.confidence_thresholds.get(class_id, self.default_confidence_threshold)\n",
    "            if pred.score.value >= threshold:\n",
    "                filtered_predictions.append(pred)\n",
    "        return filtered_predictions\n",
    "\n",
    "    def process_image(self, image_path, filename):\n",
    "        image = read_image(image_path)\n",
    "        height, width = image.shape[:2]\n",
    "        margin = 100  \n",
    "\n",
    "        slice_height = min(1280, height) if width > 2300 or height > 1500 else 640\n",
    "        slice_width = min(1280, width) if width > 2300 or height > 1500 else 640\n",
    "\n",
    "        result = get_sliced_prediction(\n",
    "            image=image_path,\n",
    "            detection_model=self.detection_model,\n",
    "            slice_height=slice_height,\n",
    "            slice_width=slice_width,\n",
    "            overlap_height_ratio=0.3,\n",
    "            overlap_width_ratio=0.3,\n",
    "            perform_standard_pred=True\n",
    "        )\n",
    "\n",
    "        predictions = result.object_prediction_list\n",
    "        predictions = self.filter_predictions_by_confidence(predictions)\n",
    "\n",
    "        boxes = [(int(pred.bbox.minx), int(pred.bbox.miny), int(pred.bbox.maxx), int(pred.bbox.maxy)) for pred in predictions]\n",
    "        scores = [pred.score.value for pred in predictions]\n",
    "\n",
    "        initial_image = cv2.imread(image_path).copy()\n",
    "        for box, pred in zip(boxes, predictions):\n",
    "            x1, y1, x2, y2 = box\n",
    "            class_id = pred.category.id\n",
    "            score = pred.score.value\n",
    "            cv2.rectangle(initial_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(initial_image, f'{class_id} {score:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n",
    "\n",
    "        # base, ext = os.path.splitext(filename)\n",
    "        # initial_output_image_path = os.path.join(self.output_dir, f'{base}_before_nms{ext}')\n",
    "        # cv2.imwrite(initial_output_image_path, initial_image)\n",
    "\n",
    "        new_predictions = []\n",
    "        visited = set()\n",
    "\n",
    "        for i in range(len(boxes)):\n",
    "            if i in visited:\n",
    "                continue\n",
    "            current_box = boxes[i]\n",
    "            has_merged = False\n",
    "            for j in range(i + 1, len(boxes)):\n",
    "                if j in visited:\n",
    "                    continue\n",
    "                if self.has_intersection(current_box, boxes[j]):\n",
    "                    merged_box = self.get_intersecting_box(current_box, boxes[j])\n",
    "                    x1, y1, x2, y2 = merged_box\n",
    "\n",
    "                    x1 = max(x1 - margin, 0)\n",
    "                    y1 = max(y1 - margin, 0)\n",
    "                    x2 = min(x2 + margin, width - 1)\n",
    "                    y2 = min(y2 + margin, height - 1)\n",
    "\n",
    "                    crop_img = image[y1:y2, x1:x2]\n",
    "                    crop_result = get_prediction(image=crop_img, detection_model=self.detection_model)\n",
    "                    # crop_result.export_visuals(export_dir=self.output_dir, file_name=f'{base}_bet{i}{ext}', text_size=0.5, rect_th=1)\n",
    "                    for pred in crop_result.object_prediction_list:\n",
    "                        new_x1 = x1 + int(pred.bbox.minx)\n",
    "                        new_y1 = y1 + int(pred.bbox.miny)\n",
    "                        new_x2 = x1 + int(pred.bbox.maxx)\n",
    "                        new_y2 = y1 + int(pred.bbox.maxy)\n",
    "                        new_predictions.append((new_x1, new_y1, new_x2, new_y2, pred.category.id, pred.score.value))\n",
    "                    visited.add(j)\n",
    "                    has_merged = True\n",
    "                    break\n",
    "            if not has_merged:\n",
    "                pred = predictions[i]\n",
    "                new_predictions.append((current_box[0], current_box[1], current_box[2], current_box[3], pred.category.id, pred.score.value))\n",
    "\n",
    "        final_boxes = [box[:4] for box in new_predictions]\n",
    "        final_scores = [box[5] for box in new_predictions]\n",
    "        final_predictions = self.apply_custom_nms(final_boxes, final_scores, new_predictions, iou_threshold=0.8)\n",
    "\n",
    "        # final_image = cv2.imread(image_path).copy()\n",
    "        # for box in final_predictions:\n",
    "        #     x1, y1, x2, y2, class_id, score = box\n",
    "        #     cv2.rectangle(final_image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "        #     cv2.putText(final_image, f'{class_id} {score:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n",
    "\n",
    "        # final_output_image_path = os.path.join(self.output_dir, f'{base}_after_nms{ext}')\n",
    "        # cv2.imwrite(final_output_image_path, final_image)\n",
    "\n",
    "        self.save_yolo_format(final_predictions, width, height, base)\n",
    "\n",
    "        return final_predictions\n",
    "\n",
    "    def save_yolo_format(self, predictions, img_width, img_height, base_filename):\n",
    "        yolo_output_path = os.path.join(self.output_dir, f'{base_filename}.txt')\n",
    "        with open(yolo_output_path, 'w') as file:\n",
    "            for pred in predictions:\n",
    "                x1, y1, x2, y2, class_id, score = pred\n",
    "                x_center = (x1 + x2) / 2.0 / img_width\n",
    "                y_center = (y1 + y2) / 2.0 / img_height\n",
    "                width = (x2 - x1) / img_width\n",
    "                height = (y2 - y1) / img_height\n",
    "                file.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "\n",
    "    def process_all_images(self):\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            futures = []\n",
    "            for filename in os.listdir(self.input_dir):\n",
    "                if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    image_path = os.path.join(self.input_dir, filename)\n",
    "                    futures.append(executor.submit(self.process_image, image_path, filename))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9399ec-5f5f-48a5-9599-2d56564e7190",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processor = ObjectDetectionProcessor(\n",
    "    ckpt_path='/Users/elinachertova/Downloads/best_2.pt',\n",
    "    input_dir='/Users/elinachertova/Downloads/hackathon_additional_dataset/dataset/test_full_for_models/',\n",
    "    output_dir='/Users/elinachertova/Downloads/drone_outputs/test_data_full2/',\n",
    "    device='cuda',  # или 'cpu'\n",
    "    confidence_thresholds={\n",
    "        0: 0.5,\n",
    "        1: 0.3,\n",
    "        2: 0.3,\n",
    "        3: 0.3,\n",
    "        4: 0.3,\n",
    "\n",
    "    }\n",
    ")\n",
    "processor.process_all_images()\n",
    "\n",
    "# для одного изображения вызывать process_image()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525dbf97-119a-439c-91c1-36293ae31fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaacc33-5ca2-4633-a20e-b442f1055549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c90ec9b-9b49-48dc-ac06-e927f909f729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66807aaf-7730-4180-84a1-d4e411280a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2318f2f-d4b5-48c1-a05e-102789d1260d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7d7d9f-dbed-4afd-911e-a0e3fbc1bcfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
